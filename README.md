Алгоритмы сортировки
1. Сортировка выбором (Selection Sort)
 * Определение: Алгоритм сортировки выбором - это алгоритм сортировки, который находит наименьший (или наибольший) элемент в неотсортированной части массива и ставит его в начало этой части.
 * Принцип работы: Алгоритм использует два вложенных цикла. Внешний цикл for проходит по позициям, которые нужно заполнить (от 0 до n-1). Внутренний цикл for ищет индекс минимального элемента в оставшейся (неотсортированной) части. После завершения внутреннего цикла найденный минимум меняется местами (swap) с элементом на текущей позиции внешнего цикла.
 * Временная сложность: O(n²) во всех случаях.
 * Обоснование сложности: Алгоритм всегда выполняет два вложенных цикла. Внешний цикл выполняется n раз, а внутренний — n, n-1, n-2... раз (в среднем n/2). Общее число сравнений всегда ~n^2/2, что в нотации Big O равно O(n²).
2. Сортировка обменом (пузырьком, Bubble Sort)
 * Определение: Алгоритм сортировки пузырьком - это алгоритм, который многократно проходит по массиву, попарно сравнивая соседние элементы и меняя их местами, если они стоят в неправильном порядке, тем самым "поднимая" большие элементы в конец.
 * Принцип работы: Использует два вложенных цикла. Внешний цикл (часто while или for) контролирует общее количество проходов по массиву (в худшем случае n-1 проход). Внутренний цикл for проходит по массиву, выполняя сравнение arr[j] с arr[j+1] и вызывая обмен (swap), если порядок нарушен.
 * Временная сложность: O(n²) (в худшем и среднем случае).
 * Обоснование сложности: В худшем случае (обратно отсортированный массив) требуется O(n) проходов, и в каждом проходе выполняется O(n) сравнений, что в итоге дает O(n^2).
3. Сортировка вставками (Insertion Sort)
 * Определение: Алгоритм сортировки вставками - это алгоритм, который строит итоговый отсортированный массив по одному элементу за раз, беря очередной элемент из входных данных и вставляя его на правильную позицию в уже отсортированную часть.
 * Принцип работы: Использует внешний цикл for, который перебирает элементы (начиная со второго). Внутри него используется внутренний цикл (обычно while), который берет текущий элемент (key) и сдвигает все элементы в отсортированной части, которые больше key, на одну позицию вправо, чтобы освободить место для вставки.
 * Временная сложность: O(n²) в худшем случае, O(n) — в лучшем.
 * Обоснование сложности: В худшем случае (обратно отсортированный массив) для вставки каждого из n элементов требуется O(n) сдвигов (O(n^2)). В лучшем случае (уже отсортированный массив) внутренний цикл не выполняется, и требуется только O(n) сравнений.
4. Сортировка слиянием (Merge Sort)
 * Определение: Алгоритм сортировки слиянием - это рекурсивный алгоритм сортировки, основанный на принципе "разделяй и властвуй". Он делит массив на две половины, рекурсивно сортирует их и затем сливает (merge) в один отсортированный массив.
 * Принцип работы: Работает через рекурсивные вызовы функции, которая делит массив пополам, пока не останутся подмассивы из одного элемента. Затем ключевая функция merge в цикле (обычно while) проходит по двум отсортированным подмассивам и, сравнивая их, собирает из них новый общий отсортированный массив.
 * Временная сложность: O(n log n) во всех случаях.
 * Обоснование сложности: Разделение массива пополам дает O(\log n) уровней рекурсии. На каждом уровне операция слияния merge должна обработать все n элементов. Перемножение этих сложностей (n операций на \log n уровней) дает O(n \log n).
5. Сортировка Шелла (Shell Sort)
 * Определение: Алгоритм сортировки Шелла - это модификация сортировки вставками, которая сначала сравнивает и сортирует элементы, стоящие далеко друг от друга (с определенным шагом gap), а затем постепенно уменьшает этот шаг до 1.
 * Принцип работы: Использует внешний цикл для итерации по последовательности шагов (например, n/2, n/4, ..., 1). Внутри него используются циклы, реализующие сортировку вставками, но сравнения и сдвиги производятся не между соседними элементами, а между элементами на расстоянии gap.
 * Временная сложность: Зависит от последовательности gap; в худшем случае O(n²), но на практике (с хорошим gap) часто приближается к O(n \log^2 n).
 * Обоснование сложности: Благодаря обменам на больших расстояниях (gap) на ранних этапах, элементы быстрее перемещаются к своим итоговым позициям. Это гарантирует, что на последнем шаге (когда gap=1 и выполняется обычная сортировка вставками), массив уже будет "почти отсортирован", что для сортировки вставками является быстрым случаем (близким к O(n)).
6. Быстрая сортировка (Quick Sort)
 * Определение: Алгоритм быстрой сортировки - это эффективный рекурсивный алгоритм, работающий по принципу "разделяй и властвуй". Он выбирает "опорный" элемент (pivot) и перераспределяет массив так, чтобы элементы меньше опорного оказались слева, а большие — справа.
 * Принцип работы: Ключевой является функция partition (разделение). Она в цикле for проходит по подмассиву, сравнивая элементы с pivot и выполняя обмены (swap) для их перемещения в нужную часть. После разделения, алгоритм рекурсивно вызывает сам себя (quickSort) для левой и правой частей.
 * Временная сложность: O(n log n) в среднем, O(n²) — в худшем случае.
 * Обоснование сложности: В среднем случае массив делится примерно пополам на каждом шаге (O(\log n) уровней рекурсии), и на каждом уровне выполняется O(n) операций разделения (O(n \log n)). В худшем случае (например, при выборе опорным элементом минимума в отсортированном массиве) деление происходит крайне неравномерно (на 1 и n-1 элемент), что приводит к O(n) уровней рекурсии (O(n^2)).
7. Пирамидальная сортировка (Heap Sort)
 * Определение: Алгоритм пирамидальной сортировки - это алгоритм сортировки, использующий структуру данных "двоичная куча" (heap). Сначала массив преобразуется в max-heap (где корень — максимальный элемент), а затем элементы поочередно извлекаются из кучи в отсортированный массив.
 * Принцип работы: Состоит из двух фаз. 1. "Построение кучи" (Build-Heap): в цикле for (от n/2 до 0) вызывается функция heapify (просеивание), чтобы превратить массив в max-heap. 2. "Сортировка": в цикле for (от n-1 до 1) корень (max элемент) меняется (swap) с последним элементом, размер кучи уменьшается, и heapify вызывается для корня, чтобы восстановить свойство кучи.
 * Временная сложность: O(n log n) во всех случаях.
 * Обоснование сложности: Построение кучи занимает O(n). Вторая фаза (сортировка) состоит из n-1 вызовов функции извлечения максимума. Каждое извлечение (обмен и вызов heapify) занимает O(\log n) времени. Итоговая сложность O(n \log n).
Алгоритмы поиска
1. Последовательный (линейный) поиск
 * Определение: Алгоритм последовательного поиска - это простейший метод поиска, который заключается в последовательном переборе всех элементов массива по одному до тех пор, пока не будет найдено совпадение или не закончится массив.
 * Принцип работы: Использует один цикл for (от 0 до n-1). Внутри цикла выполняется операция сравнения (if arr[i] == target). Если совпадение найдено, функция немедленно возвращает (return) индекс. Если цикл завершился без совпадений, возвращается -1.
 * Временная сложность: O(n).
 * Обоснование сложности: В худшем случае (элемент последний или отсутствует) алгоритм должен выполнить n операций сравнения, чтобы проверить каждый элемент.
2. Бинарный поиск
 * Определение: Алгоритм бинарного поиска - это эффективный алгоритм поиска в отсортированном массиве, который на каждом шаге делит область поиска пополам.
 * Принцип работы: Использует цикл while (пока левая граница left <= правой right). Внутри цикла вычисляется средний индекс (mid). Искомый элемент сравнивается со средним (arr[mid]). Если искомое значение больше, поиск продолжается в правой половине (сдвигается left), если меньше — в левой (сдвигается right).
 * Временная сложность: O(log n).
 * Обоснование сложности: На каждой итерации область поиска сокращается вдвое. Чтобы сократить массив размером n до 1 элемента, требуется \log_2 n таких делений.
3. Интерполирующий поиск
 * Определение: Алгоритм интерполирующего поиска - это улучшенный вариант бинарного поиска для отсортированных и равномерно распределенных данных. Он "предсказывает" (интерполирует) позицию искомого элемента.
 * Принцип работы: Похож на бинарный поиск (цикл while и сдвиг границ), но вместо простого вычисления середины (mid), позиция (pos) вычисляется по специальной формуле линейной интерполяции. Эта формула учитывает значения искомого элемента и крайних элементов диапазона.
 * Временная сложность: O(log log n) — в среднем (при равномерном распределении), O(n) — в худшем случае.
 * Обоснование сложности: При равномерном распределении формула очень точно предсказывает позицию, сужая диапазон поиска экспоненциально быстрее, чем деление пополам (O(log log n)). Если же данные распределены неравномерно (например, [1, 2, 1000]), поиск вырождается в линейный (O(n)).
4. Поиск по Фибоначчи
 * Определение: Алгоритм поиска по Фибоначчи - это алгоритм поиска в отсортированном массиве, который для сужения диапазона поиска использует деление на части, пропорциональные числам Фибоначчи.
 * Принцип работы: Сначала в цикле while генерируются числа Фибоначчи (F_m, F_{m-1}, F_{m-2}), пока F_m не станет больше или равно n. Затем в цикле поиска проверяется элемент на позиции, рассчитанной с помощью F_{m-2}. В зависимости от результата сравнения, диапазон сужается, а числа Фибоначчи "сдвигаются" вниз (пересчитываются).
 * Временная сложность: O(log n).
 * Обоснование сложности: Процесс сужения диапазона поиска логарифмический, как и в бинарном поиске. Главное преимущество в том, что алгоритм использует только операции сложения и вычитания (для вычисления индексов), избегая деления или умножения, что может быть эффективнее на некоторых вычислительных системах.
