### Алгоритмы сортировки

1. **Сортировка выбором (Selection Sort)**  
   * **Определение**: Сортировка выбором — это алгоритм, который находит наименьший (или наибольший) элемент в неотсортированной части массива и ставит его в начало этой части.  
   * **Принцип работы**: Алгоритм использует два вложенных цикла. Внешний цикл for проходит по позициям, которые нужно заполнить (от 0 до n-1). Внутренний цикл for ищет индекс минимального элемента в оставшейся (неотсортированной) части. После завершения внутреннего цикла найденный минимум меняется местами (swap) с элементом на текущей позиции внешнего цикла.  
   * **Временная сложность**: O(n²)  
   * **Обоснование сложности**: Алгоритм всегда выполняет два вложенных цикла. Внешний цикл выполняется n раз, а внутренний — n, n-1, n-2... раз (в среднем n/2). Общее число сравнений всегда ~n²/2, что в нотации Big O равно O(n²).

2. **Сортировка обменом (пузырьком, Bubble Sort)**  
   * **Определение**: Сортировка пузырьком — это алгоритм, который многократно проходит по массиву, попарно сравнивая соседние элементы и меняя их местами, если они стоят в неправильном порядке, тем самым "поднимая" большие элементы в конец.  
   * **Принцип работы**: Использует два вложенных цикла. Внешний цикл (часто while или for) контролирует общее количество проходов по массиву (в худшем случае n-1 проход). Внутренний цикл for проходит по массиву, выполняя сравнение arr[j] с arr[j+1] и вызывая обмен (swap), если порядок нарушен.  
   * **Временная сложность**: O(n²)  
   * **Обоснование сложности**: В худшем случае (обратно отсортированный массив) требуется O(n) проходов, и в каждом проходе выполняется O(n) сравнений, что в итоге даёт O(n²). На практике алгоритм не адаптируется к частично отсортированным данным без оптимизаций, поэтому сложность остаётся квадратичной.

3. **Сортировка вставками (Insertion Sort)**  
   * **Определение**: Сортировка вставками — это алгоритм, который строит итоговый отсортированный массив по одному элементу за раз, беря очередной элемент из входных данных и вставляя его на правильную позицию в уже отсортированную часть.  
   * **Принцип работы**: Использует внешний цикл for, который перебирает элементы (начиная со второго). Внутри него используется внутренний цикл (обычно while), который берет текущий элемент (key) и сдвигает все элементы в отсортированной части, которые больше key, на одну позицию вправо, чтобы освободить место для вставки.  
   * **Временная сложность**: O(n²)  
   * **Обоснование сложности**: В худшем случае (обратно отсортированный массив) для вставки каждого из n элементов требуется O(n) сдвигов, что даёт O(n²). Однако при почти отсортированных данных алгоритм работает близко к O(n), но общая оценка по Big O остаётся O(n²), так как это верхняя граница.

4. **Сортировка слиянием (Merge Sort)**  
   * **Определение**: Сортировка слиянием — это рекурсивный алгоритм, основанный на принципе "разделяй и властвуй". Он делит массив на две половины, рекурсивно сортирует их и затем сливает (merge) в один отсортированный массив.  
   * **Принцип работы**: Работает через рекурсивные вызовы функции, которая делит массив пополам, пока не останутся подмассивы из одного элемента. Затем ключевая функция merge в цикле (обычно while) проходит по двум отсортированным подмассивам и, сравнивая их, собирает из них новый общий отсортированный массив.  
   * **Временная сложность**: O(n log n)  
   * **Обоснование сложности**: Разделение массива пополам даёт O(log n) уровней рекурсии. На каждом уровне операция слияния merge должна обработать все n элементов. Перемножение этих сложностей (n операций на log n уровней) даёт O(n log n).

5. **Сортировка Шелла (Shell Sort)**  
   * **Определение**: Сортировка Шелла — это модификация сортировки вставками, которая сначала сравнивает и сортирует элементы, стоящие далеко друг от друга (с определённым шагом gap), а затем постепенно уменьшает этот шаг до 1.  
   * **Принцип работы**: Использует внешний цикл для итерации по последовательности шагов (например, n/2, n/4, ..., 1). Внутри него используются циклы, реализующие сортировку вставками, но сравнения и сдвиги производятся не между соседними элементами, а между элементами на расстоянии gap.  
   * **Временная сложность**: O(n²)  
   * **Обоснование сложности**: Теоретически, при неудачной последовательности шагов (например, классической n/2, n/4...), сложность может достигать O(n²). Хотя на практике с хорошими последовательностями (например, Кнута или Седжвика) сложность приближается к O(n log² n), в общем случае без фиксированной последовательности гарантированная верхняя граница — O(n²).

6. **Быстрая сортировка (Quick Sort)**  
   * **Определение**: Быстрая сортировка — это эффективный рекурсивный алгоритм, работающий по принципу "разделяй и властвуй". Он выбирает "опорный" элемент (pivot) и перераспределяет массив так, чтобы элементы меньше опорного оказались слева, а большие — справа.  
   * **Принцип работы**: Ключевой является функция partition (разделение). Она в цикле for проходит по подмассиву, сравнивая элементы с pivot и выполняя обмены (swap) для их перемещения в нужную часть. После разделения, алгоритм рекурсивно вызывает сам себя (quickSort) для левой и правой частей.  
   * **Временная сложность**: O(n²)  
   * **Обоснование сложности**: В худшем случае (например, при выборе крайнего элемента в уже отсортированном массиве) деление происходит крайне неравномерно, что приводит к O(n) уровней рекурсии и общей сложности O(n²). Хотя средняя сложность — O(n log n), Big O описывает **верхнюю границу**, поэтому указывается O(n²).

7. **Пирамидальная сортировка (Heap Sort)**  
   * **Определение**: Пирамидальная сортировка — это алгоритм, использующий структуру данных "двоичная куча" (heap). Сначала массив преобразуется в max-heap (где корень — максимальный элемент), а затем элементы поочередно извлекаются из кучи в отсортированный массив.  
   * **Принцип работы**: Состоит из двух фаз. 1. "Построение кучи" (Build-Heap): в цикле for (от n/2 до 0) вызывается функция heapify (просеивание), чтобы превратить массив в max-heap. 2. "Сортировка": в цикле for (от n-1 до 1) корень (max элемент) меняется (swap) с последним элементом, размер кучи уменьшается, и heapify вызывается для корня, чтобы восстановить свойство кучи.  
   * **Временная сложность**: O(n log n)  
   * **Обоснование сложности**: Построение кучи занимает O(n). Вторая фаза (сортировка) состоит из n-1 вызовов функции извлечения максимума. Каждое извлечение (обмен и вызов heapify) занимает O(log n) времени. Итоговая сложность O(n log n).

---

### Алгоритмы поиска

1. **Последовательный (линейный) поиск**  
   * **Определение**: Последовательный поиск — это простейший метод поиска, который заключается в последовательном переборе всех элементов массива по одному до тех пор, пока не будет найдено совпадение или не закончится массив.  
   * **Принцип работы**: Использует один цикл for (от 0 до n-1). Внутри цикла выполняется операция сравнения (if arr[i] == target). Если совпадение найдено, функция немедленно возвращает (return) индекс. Если цикл завершился без совпадений, возвращается -1.  
   * **Временная сложность**: O(n)  
   * **Обоснование сложности**: В худшем случае (элемент последний или отсутствует) алгоритм должен выполнить n операций сравнения, чтобы проверить каждый элемент.

2. **Бинарный поиск**  
   * **Определение**: Бинарный поиск — это эффективный алгоритм поиска в отсортированном массиве, который на каждом шаге делит область поиска пополам.  
   * **Принцип работы**: Использует цикл while (пока левая граница left <= правой right). Внутри цикла вычисляется средний индекс (mid). Искомый элемент сравнивается со средним (arr[mid]). Если искомое значение больше, поиск продолжается в правой половине (сдвигается left), если меньше — в левой (сдвигается right).  
   * **Временная сложность**: O(log n)  
   * **Обоснование сложности**: На каждой итерации область поиска сокращается вдвое. Чтобы сократить массив размером n до 1 элемента, требуется log₂ n таких делений.

3. **Интерполирующий поиск**  
   * **Определение**: Интерполирующий поиск — это улучшенный вариант бинарного поиска для отсортированных и равномерно распределённых данных. Он "предсказывает" (интерполирует) позицию искомого элемента.  
   * **Принцип работы**: Похож на бинарный поиск (цикл while и сдвиг границ), но вместо простого вычисления середины (mid), позиция (pos) вычисляется по специальной формуле линейной интерполяции. Эта формула учитывает значения искомого элемента и крайних элементов диапазона.  
   * **Временная сложность**: O(n)  
   * **Обоснование сложности**: При неравномерном распределении данных (например, экспоненциальном или с выбросами) алгоритм может вырождаться в линейный поиск. Поскольку Big O описывает **наихудшую возможную** производительность, указывается O(n), хотя в идеальных условиях (равномерное распределение) сложность может достигать O(log log n).

4. **Поиск по Фибоначчи**  
   * **Определение**: Поиск по Фибоначчи — это алгоритм поиска в отсортированном массиве, который для сужения диапазона поиска использует деление на части, пропорциональные числам Фибоначчи.  
   * **Принцип работы**: Сначала в цикле while генерируются числа Фибоначчи (Fₘ, Fₘ₋₁, Fₘ₋₂), пока Fₘ не станет больше или равно n. Затем в цикле поиска проверяется элемент на позиции, рассчитанной с помощью Fₘ₋₂. В зависимости от результата сравнения, диапазон сужается, а числа Фибоначчи "сдвигаются" вниз (пересчитываются).  
   * **Временная сложность**: O(log n)  
   * **Обоснование сложности**: Процесс сужения диапазона поиска логарифмический, как и в бинарном поиске. Главное преимущество в том, что алгоритм использует только операции сложения и вычитания (для вычисления индексов), избегая деления или умножения, что может быть эффективнее на некоторых вычислительных системах.
